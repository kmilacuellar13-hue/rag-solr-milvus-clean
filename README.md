ğŸ§  Taller RAG con Solr y Milvus â€” Entrega Final

Este repositorio implementa dos pipelines de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG):

RAG lÃ©xico usando Apache Solr (BM25)

RAG vectorial usando Milvus (embeddings)

Ambos motores se exponen mediante una API unificada en FastAPI, y el sistema incluye scripts automÃ¡ticos para:

ConversiÃ³n del corpus

IndexaciÃ³n en Solr y Milvus

EvaluaciÃ³n del desempeÃ±o

GeneraciÃ³n de mÃ©tricas y grÃ¡ficas comparativas

El proyecto cumple todos los criterios del taller RAG Solrâ€“Milvus: indexaciÃ³n completa, API funcional, evaluador operativo y mÃ©tricas obtenidas.

ğŸ“ Estructura del proyecto
rag-solr-milvus/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus/
â”‚       â”œâ”€â”€ corpus_bloques_100.csv      # Corpus original
â”‚       â””â”€â”€ corpus_texto.jsonl          # Corpus convertido (JSONL)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/                            # API unificada (FastAPI)
â”‚   â”œâ”€â”€ indexer/                        # Scripts de conversiÃ³n, indexaciÃ³n y evaluaciÃ³n
â”‚   â”œâ”€â”€ solr/                           # ConfiguraciÃ³n del core rag2
â”‚   â””â”€â”€ milvus/                         # Notas de la colecciÃ³n vectorial
â”œâ”€â”€ reports/                            # Resultados generados por el evaluador
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

âš™ï¸ Requisitos

Docker + Docker Compose

Python 3.10+ (para ejecutar scripts de indexaciÃ³n/evaluaciÃ³n desde host)

Archivo de entrada:
data/corpus/corpus_bloques_100.csv

ğŸš€ EjecuciÃ³n del proyecto
1ï¸âƒ£ Levantar el stack (Solr, Milvus, MinIO, ETCD, API)
docker compose up -d --build


Servicios incluidos:

Servicio	Rol
solr	BÃºsqueda BM25
milvus	BÃºsqueda vectorial
etcd	Coordinador de Milvus
minio	Almacenamiento de snapshots
api	API unificada FastAPI

Verificar:

docker compose ps

2ï¸âƒ£ ConversiÃ³n e indexaciÃ³n
Convertir CSV â†’ JSONL
python services/indexer/convertir_csv.py ^
  --input data/corpus/corpus_bloques_100.csv ^
  --output data/corpus/corpus_texto.jsonl ^
  --text-col texto_limpio

Indexar en Solr
python services/indexer/indexar_solr.py ^
  --solr http://localhost:8983/solr/rag2 ^
  --input data/corpus/corpus_texto.jsonl

Indexar en Milvus
python services/indexer/index_milvus.py ^
  --input data/corpus/corpus_texto.jsonl ^
  --host localhost ^
  --port 19530

ğŸ” 3ï¸âƒ£ Probar la API
Salud general
curl http://localhost:8000/health

Consultar BM25 (Solr)
curl "http://localhost:8000/solr?q=paz territorial&k=5"

Consultar vectorial (Milvus)
curl "http://localhost:8000/milvus?q=paz territorial&k=5"

UI interactiva

ğŸ‘‰ http://localhost:8000/docs

ğŸ§ª 4ï¸âƒ£ EvaluaciÃ³n (Solr vs Milvus)

El evaluador utiliza:

queries_gold.jsonl (queries reales)

corpus_texto.jsonl (documentos convertidos)

Ejecutar:
python services/evaluator/evaluator.py


Esto produce:

ğŸ“„ reports/metrics_per_query.csv
ğŸ“„ reports/metrics_summary.csv
ğŸ“Š 5 grÃ¡ficos comparativos:

Latencia

Recall@k

MRR

nDCG

ROUGE-L

ğŸ“Š Resultados de la evaluaciÃ³n (finales)

Con k = 5, ambos motores lograron recall perfecto.
Resultados globales:

MÃ©trica	Milvus	Solr
Recall@k	1.00	1.00
MRR	0.939	0.894
nDCG	0.940	0.921
ROUGE-L	0.161	0.0026
Latencia (s)	0.263	0.136
ğŸ“ Conclusiones

Ambos motores alcanzan Recall@5 = 1.0, lo que demuestra que Solr y Milvus recuperan los documentos correctos dentro del top-k.

Milvus supera a Solr en mÃ©tricas de ranking (MRR y nDCG), por lo que devuelve los documentos correctos en posiciones mÃ¡s altas del ranking.

Solr es mÃ¡s rÃ¡pido, con latencias alrededor de 130 ms, lo cual es consistente con motores BM25 optimizados para matching lÃ©xico.

Milvus ofrece una calidad semÃ¡ntica notablemente superior, con ROUGE-L dos Ã³rdenes de magnitud mayor, evidenciando que los embeddings capturan mejor el contenido conceptual.

La combinaciÃ³n Solr + Milvus en una API unificada permite construir pipelines hÃ­bridos y escalables para tareas RAG.



