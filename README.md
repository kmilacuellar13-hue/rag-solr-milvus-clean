# ðŸ§  Taller RAG con Solr y Milvus

Este proyecto implementa dos backends de recuperaciÃ³n para un pipeline tipo RAG:

- ðŸ”¹ **Solr** (bÃºsqueda lÃ©xica con BM25)
- ðŸ”¹ **Milvus** (bÃºsqueda vectorial con embeddings)

Ambos se exponen a travÃ©s de una **API unificada en FastAPI**, que permite consultar:

- `/solr` â†’ bÃºsqueda lÃ©xica
- `/milvus` â†’ bÃºsqueda vectorial
- `/ask` â†’ selector de backend (`solr`, `milvus` o ambos)

---

## 0. Requisitos

- ðŸ³ **Docker** y **Docker Compose**
- ðŸ **Python 3.10+** (para ejecutar scripts de conversiÃ³n / indexaciÃ³n / evaluaciÃ³n)
- Archivo de datos:
  - `data/corpus/corpus_bloques_100.csv` (corpus original en CSV)

---

## 1. Estructura mÃ­nima del proyecto

```bash
rag-solr-milvus/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus/
â”‚       â”œâ”€â”€ corpus_bloques_100.csv      # Corpus original
â”‚       â””â”€â”€ corpus_texto.jsonl          # Corpus convertido (se genera)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ app.py                      # API FastAPI (Solr & Milvus)
â”‚   â”œâ”€â”€ indexer/
â”‚   â”‚   â”œâ”€â”€ convertir_csv.py
â”‚   â”‚   â”œâ”€â”€ indexar_solr.py
â”‚   â”‚   â””â”€â”€ index_milvus.py
â”‚   â”œâ”€â”€ solr/                           # ConfiguraciÃ³n del core rag2
â”‚   â””â”€â”€ milvus/                         # Notas de la colecciÃ³n
â”œâ”€â”€ reports/                            # MÃ©tricas y grÃ¡ficos (se generan)
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

2. Levantar los servicios (Solr, Milvus, API)
Desde la raÃ­z del proyecto:

```bash
docker compose up -d --build
```
Esto levanta:

* solr â†’ en http://localhost:8983
* milvus â†’ puerto 19530
* api (FastAPI) â†’ http://localhost:8000
* etcd, minio â†’ dependencias de Milvus
* solr-init â†’ inicializa el core rag2

Verificar:

```bash
docker compose ps
```

3. Preparar el corpus (CSV â†’ JSONL)
Solo si aÃºn no existe data/corpus/corpus_texto.jsonl.

3.1. Crear entorno (opcional, pero recomendado)
```bash
python -m venv .venv
.venv\Scripts\activate
```
3.2. Instalar dependencias de los scripts
```bash
pip install -r services/indexer/requirements.txt
```
3.3. Convertir el CSV a JSONL
```bash
python services/indexer/convertir_csv.py ^
  --input data/corpus/corpus_bloques_100.csv ^
  --output data/corpus/corpus_texto.jsonl ^
  --text-col texto_limpio
```
texto_limpio es el nombre de la columna que contiene el texto en el CSV.

4. Indexar en Solr y Milvus
4.1. Indexar en Solr (BM25)
```bash
python services/indexer/indexar_solr.py
```
Este script:

* Hace ping a [http://localhost:8983/solr/rag2](http://localhost:8983/solr/#/rag2/query)
* Lee data/corpus/corpus_texto.jsonl
* Inserta cada documento en el core rag2 con campos:
  *  id
  *  text

Si todo sale bien verÃ¡s algo como:

```text
Ping: {'status': 'OK', ...}
Indexed N documents into Solr core 'rag2'
```

4.2. Indexar en Milvus (vectorial)
```bash
python services/indexer/index_milvus.py ^
  --input data/corpus/corpus_texto.jsonl ^
  --host 127.0.0.1 ^
  --port 19530
```
Este script:
* Conecta a Milvus en 127.0.0.1:19530
* Crea la colecciÃ³n corpus_rag (si no existe)
* Usa el modelo paraphrase-multilingual-MiniLM-L12-v2 para generar embeddings

Salida tÃ­pica:
```text
Indexando: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:15]
OK -> 725 chunks en colecciÃ³n 'corpus_rag'
```

5. Probar la API paso a paso
5.1. Comprobar que la API estÃ¡ viva
```bash
curl http://localhost:8000/health
```
Respuesta esperada:

```json
{"status":"ok"}
```
5.2. Probar endpoint Solr (/solr)

Ejemplo:

```bash
curl "http://localhost:8000/solr?q=paz territorial&k=5"
```
5.3. Probar endpoint Milvus (/milvus)
```bash
curl "http://localhost:8000/milvus?q=paz territorial&k=5"
```
Respuesta similar, con "source": "milvus".

5.4. Probar endpoint unificado /ask
```bash
curl "http://localhost:8000/ask?query=paz territorial&backend=solr&k=5"
curl "http://localhost:8000/ask?query=paz territorial&backend=milvus&k=5"
curl "http://localhost:8000/ask?query=paz territorial&backend=both&k=5"
backend=solr â†’ solo Solr
```
* backend=milvus â†’ solo Milvus
* backend=both â†’ concatena resultados de ambos backends

5.5. UI interactiva (Swagger / Redoc)
Abrir en el navegador:

* Swagger: ðŸ‘‰ http://localhost:8000/docs
* Redoc: ðŸ‘‰ http://localhost:8000/redoc

Desde ahÃ­ puedes probar /solr, /milvus y /ask con formularios.

6. Evaluar el desempeÃ±o (opcional, pero recomendado)
Si quieres medir mÃ©tricas tipo recall, MRR, nDCG, etc., usa el evaluador.

6.1. Archivo de queries + gold
El evaluador usa:
* data/queries_gold.jsonl
con campos:
  * query â†’ texto de la pregunta
  * gold_ids â†’ lista de IDs relevantes (por ejemplo ["doc_000000"])

6.2. Ejecutar el evaluador
```bash
python services/evaluator/evaluator.py
```
Esto:
* EvalÃºa primero Solr, luego Milvus
* Llama a la API /ask con backend=solr y backend=milvus

Calcula mÃ©tricas por query y resumen agregados

Genera:

* reports/metrics_per_query.csv
* reports/metrics_summary.csv

GrÃ¡ficos:
  * reports/latency_comparison.png
  * reports/recall_comparison.png
  * reports/mrr_comparison.png
  * reports/ndcg_comparison.png
  * reports/rougeL_comparison.png


```text
Resumen:
           latency  recall_at_k       mrr      ndcg    rougeL
backend
milvus   0.263548          1.0  0.939394  0.940064  0.161310
solr     0.136780          1.0  0.893939  0.920994  0.002627
```

7. Accesos rÃ¡pidos
* ðŸ§  API FastAPI: http://localhost:8000
* ðŸ“š Docs Swagger: http://localhost:8000/docs
* ðŸ”Ž Solr UI: http://localhost:8983/solr/#/rag2/query
* ðŸ§® Milvus: conecta vÃ­a Python usando pymilvus y host=localhost, port=19530
